{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading and package importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import adjusted_rand_score,silhouette_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib notebook\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('data/tp2_data.csv').drop('Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = original_data[original_data.type != 'nuclear explosion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {'x':6371 * np.cos(original_data['latitude'].values * np.pi/180) * np.cos(original_data['longitude'].values * np.pi/180) , 'y': 6371 * np.cos(original_data['latitude'].values *np.pi/180) * np.sin(original_data['longitude'].values * np.pi/180) , 'z': 6371 * np.sin(original_data['latitude'].values * np.pi/180), 'fault': original_data['fault'], 'latitude': original_data['latitude'], 'longitude': original_data['longitude'] } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=info,columns=['x','y','z','fault','latitude','longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes(labels,lon,lat, alpha=0.5, edge = 'k'):\n",
    "    \n",
    "    \"\"\"Plot seismic events using Mollweide projection.\n",
    "    Arguments are the cluster labels and the longitude and latitude\n",
    "    vectors of the events\"\"\"\n",
    "    \n",
    "    img = plt.imread(\"Mollweide_projection_SW.jpg\")\n",
    "     \n",
    "    plt.figure(figsize = (10,5),frameon = False)    \n",
    "    x = lon/180*np.pi\n",
    "    y = lat/180*np.pi\n",
    "    ax = plt.subplot(111, projection = \"mollweide\")\n",
    "    print(ax.get_xlim(), ax.get_ylim())\n",
    "    t = ax.transData.transform(np.vstack((x,y)).T)\n",
    "    print(np.min(np.vstack((x,y)).T,axis = 0))\n",
    "    print(np.min(t,axis = 0))\n",
    "    clims = np.array([(-np.pi,0),(np.pi,0),(0,-np.pi/2),(0,np.pi/2)])\n",
    "    lims = ax.transData.transform(clims)\n",
    "    plt.close()\n",
    "    plt.figure(figsize = (10,5),frameon = False)    \n",
    "    plt.subplot(111)\n",
    "    plt.imshow(img,zorder = 0,extent = [lims[0,0],lims[1,0],lims[2,1],lims[3,1]],aspect = 1)        \n",
    "    x = t[:,0]\n",
    "    y = t[:,1]\n",
    "    nots = np.zeros(len(labels)).astype(bool)\n",
    "    diffs = np.unique(labels)    \n",
    "    ix = 0   \n",
    "    for lab in diffs[diffs >= 0]:        \n",
    "        mask = labels == lab\n",
    "        nots = np.logical_or(nots,mask)        \n",
    "        plt.plot(x[mask], y[mask],'o', markersize = 4, mew = 1,zorder = 1,alpha = alpha, markeredgecolor = edge)\n",
    "        ix = ix+1                    \n",
    "    mask = np.logical_not(nots)    \n",
    "    if np.sum(mask) > 0:\n",
    "        plt.plot(x[mask], y[mask], '.', markersize = 1, mew = 1,markerfacecolor = 'w', markeredgecolor = edge)\n",
    "    plt.axis('off')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rand_index(df, labels, groups):\n",
    "    TP = TN = FP = FN = 0\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        SL = labels[i] == labels[(i+1):]\n",
    "        SG = groups[i] == groups[(i+1):]\n",
    "        \n",
    "        TP_aux = np.logical_and(SG,SL)\n",
    "        FP_aux = np.logical_and(np.logical_not(SG), SL)\n",
    "        FN_aux = np.logical_and(SG, np.logical_not(SL))\n",
    "        TN_aux = np.logical_and(np.logical_not(SG), np.logical_not(SL))\n",
    "        \n",
    "        TP += np.sum(TP_aux)\n",
    "        TN += np.sum(TN_aux)\n",
    "        FP += np.sum(FP_aux)\n",
    "        FN += np.sum(FN_aux)\n",
    "        \n",
    "        Rand_score = (TP + TN) / (TP + TN + FP + FN)\n",
    "        Precision = TP / (TP + FP)\n",
    "        Recall = TP / (TP + FN)\n",
    "        F1 = 2 * Precision * Recall / (Precision + Recall)\n",
    "        \n",
    "        return([Rand_score, Precision, Recall, F1, silhouette_score(df.loc[:,['x','y','z']],labels), adjusted_rand_score(labels,groups)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon extraction for DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knn_model = KNeighborsClassifier(n_neighbors = 4).fit(data.loc[:,['x','y','z']], np.zeros(len(data)))\n",
    "\n",
    "dists = np.sort(Knn_model.kneighbors()[0][:,3])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_data = np.linspace(0,len(data),num = len(data) + 1)\n",
    "y_data = dists\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x = x_data,\n",
    "    y = y_data,\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "data_plot = [trace]\n",
    "\n",
    "py.iplot(data_plot, filename='Bazofe')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Alghoritms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in [1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 0]:\n",
    "    samples = data.sample(round(len(data)*(1-it)))\n",
    "    kmeans_labels = KMeans(n_clusters = 27, random_state=3).fit_predict(samples.loc[:,['x','y','z']])\n",
    "    print(silhouette_score(samples.loc[:,['x','y','z']],kmeans_labels), adjusted_rand_score(kmeans_labels,samples[\"fault\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_metrics_Kmeans(df, cluster_range, plot_metric = False, plot_clusters = False, get = True):\n",
    "    \n",
    "    label_array = np.zeros((df.shape[0],1 + max(cluster_range)))\n",
    "    \n",
    "    for n_clust in cluster_range:\n",
    "        kmeans_labels = KMeans(n_clusters = n_clust).fit_predict(df.loc[:,['x','y','z']])\n",
    "        label_array[:,n_clust] = kmeans_labels\n",
    "                \n",
    "    if plot_metric or get : \n",
    "        metrics_df = pd.DataFrame(index = [], columns = ['Rand Score', 'Precision', 'Recall', 'F1 score', \n",
    "                                                         'Silhouette score', 'Adjusted Rand Score'])\n",
    "        \n",
    "        for n_clust in cluster_range:\n",
    "            metrics_df.loc[n_clust] = rand_index(df, label_array[:,n_clust] , df[\"fault\"])\n",
    "\n",
    "        if get:\n",
    "            print(metrics_df)\n",
    "        if plot_metric:\n",
    "            metrics_df.plot(subplots = True) \n",
    "            \n",
    "    if plot_clusters:\n",
    "        for n_clust in cluster_range:\n",
    "            plot_classes(label_array[:,n_clust], df.longitude, df.latitude)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot_metrics_Kmeans(data,range(3,50), plot_metric = True, get = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gmix_labels = GaussianMixture(n_components = 5, random_state=4).fit(data.loc[:,['x','y','z']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corr(covs):\n",
    "\n",
    "    idx = [\"Cluster \" + str(i) for i in range(1,len(covs)+1)]\n",
    "    cols = [\"Cluster \" + str(i) for i in range(1,len(covs)+1)]\n",
    "\n",
    "    df_corrs = pd.DataFrame(index=idx, columns=cols)\n",
    "\n",
    "    for i in range(0,5):\n",
    "        corr=[]\n",
    "        for j in range(0,5):\n",
    "            a = np.matmul(np.transpose(covs[i]),covs[j])\n",
    "            b = np.matmul(np.transpose(covs[j]),covs[i])\n",
    "\n",
    "            xx = np.matmul(np.transpose(covs[i]),covs[i])\n",
    "            yy = np.matmul(np.transpose(covs[j]),covs[j])\n",
    "\n",
    "            trace = np.trace(np.matmul(a,b))\n",
    "\n",
    "            x = np.trace(np.matmul(np.transpose(xx),xx))\n",
    "            y = np.trace(np.matmul(yy,yy))\n",
    "\n",
    "            corr.append(trace/np.sqrt(x*y))\n",
    "\n",
    "        df_corrs.iloc[i]=corr\n",
    "    \n",
    "    return df_corrs.astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corrs = make_corr(covs)\n",
    "df_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df_corrs.astype(float), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_metrics_Gmix(df, cluster_range, plot_metric = False, plot_clusters = True, get = True):\n",
    "    \n",
    "    label_array = np.zeros((data.shape[0],1 + max(cluster_range)))\n",
    "    \n",
    "    for n_clust in cluster_range:\n",
    "        Gmix_labels = GaussianMixture(n_components = n_clust).fit_predict(df.loc[:,['x','y','z']])\n",
    "        label_array[:,n_clust] = Gmix_labels\n",
    "                \n",
    "    if plot_metric or get : \n",
    "        metrics_df = pd.DataFrame(index = [], columns = ['Rand Score', 'Precision', 'Recall', 'F1 score',\n",
    "                                                         'Silhouette score', 'Adjusted Rand Score'])\n",
    "\n",
    "        for n_clust in cluster_range:\n",
    "            metrics_df.loc[n_clust] = rand_index(df, label_array[:,n_clust], df[\"fault\"])\n",
    "        \n",
    "        if get:\n",
    "            print(metrics_df)\n",
    "    \n",
    "        if plot_metric:\n",
    "            metrics_df.plot(subplots = True)\n",
    "        \n",
    "    if plot_clusters:\n",
    "        for n_clust in cluster_range:\n",
    "            plot_classes(label_array[:,n_clust], df.longitude, df.latitude)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_plot_metrics_Gmix(data, range(3,50), plot_metric = True, get = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_metrics_DB(df, eps_range, plot_metric = False, plot_clusters = False, get = True):\n",
    "    \n",
    "    label_array = np.zeros((len(eps_range), 1 + df.shape[0]))\n",
    "    label_array[:,0] = eps_range\n",
    "    \n",
    "    for count in range(len(eps_range)):\n",
    "        \n",
    "        DB_labels = DBSCAN(eps = eps_range[count]).fit_predict(df.loc[:,['x','y','z']])\n",
    "        label_array[count ,1:] = DB_labels\n",
    "                    \n",
    "    if plot_metric or get : \n",
    "        \n",
    "        metrics_df = pd.DataFrame(index = eps_range ,columns = ['Rand Score', 'Precision', 'Recall', 'F1 score',\n",
    "                                                                'Silhouette score', 'Adjusted Rand Score'])\n",
    "    \n",
    "        for line in range(metrics_df.shape[0]):\n",
    "            metrics_df.iloc[line] = rand_index(df, label_array[line,1:], df[\"fault\"])\n",
    "        \n",
    "        if get:\n",
    "            print(metrics_df)\n",
    "    \n",
    "        if plot_metric:\n",
    "            metrics_df.plot()\n",
    "        \n",
    "    if plot_clusters:\n",
    "        for count in label_array[:,1]:\n",
    "            plot_classes(label_array[count,2:], df.longitude, df.latitude)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plot_metrics_DB(data,np.linspace(200, 600, num = 200),plot_metric = True, get = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
